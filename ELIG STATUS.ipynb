{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a831e2b7-20e6-4195-a564-4675bce8e06e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Read current eligibility data\n",
    "print(\"=== CURRENT ELIGIBILITY DATA ===\")\n",
    "eligibility_df = spark.table(\"healthanalytics.eligibility\")\n",
    "eligibility_df.show(10)\n",
    "\n",
    "# Check the current schema\n",
    "eligibility_df.printSchema()\n",
    "\n",
    "print(\"Current eligibility status distribution:\")\n",
    "eligibility_df.groupBy(\"eligibility_status\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d444b93-77c6-43a6-ac17-829453950091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def implement_eligibility_scd2(target_table, source_df, key_column=\"member_id\"):\n",
    "    \"\"\"\n",
    "    Implement SCD Type 2 for eligibility table with proper healthcare date handling\n",
    "    \n",
    "    This tracks:\n",
    "    - Coverage terminations and reactivations\n",
    "    - Plan changes\n",
    "    - Eligibility period overlaps\n",
    "    - Compliance audit trail\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== ELIGIBILITY SCD TYPE 2 IMPLEMENTATION ===\")\n",
    "    \n",
    "    # Read current eligibility table\n",
    "    try:\n",
    "        current_eligibility = spark.table(target_table)\n",
    "    except Exception:\n",
    "        # If SCD2 table doesn't exist, create from base table\n",
    "        current_eligibility = spark.table(\"healthanalytics.eligibility\")\n",
    "        \n",
    "        # Add SCD2 columns to existing data\n",
    "        current_eligibility = current_eligibility \\\n",
    "            .withColumn(\"record_start_date\", col(\"eligibility_start_date\")) \\\n",
    "            .withColumn(\"record_end_date\", lit(\"9999-12-31\")) \\\n",
    "            .withColumn(\"is_current_record\", lit(True)) \\\n",
    "            .withColumn(\"change_reason\", lit(\"Initial Load\")) \\\n",
    "            .withColumn(\"version_number\", lit(1)) \\\n",
    "            .withColumn(\"created_timestamp\", current_timestamp())\n",
    "        \n",
    "        # Save initial SCD2 table\n",
    "        current_eligibility.write.mode(\"overwrite\").saveAsTable(f\"{target_table}_scd2\")\n",
    "        print(\"Created initial SCD2 eligibility table\")\n",
    "    \n",
    "    # Display current active eligibility records\n",
    "    active_records = current_eligibility.filter(col(\"is_current_record\") == True)\n",
    "    print(f\"Current active eligibility records: {active_records.count()}\")\n",
    "    active_records.show()\n",
    "    \n",
    "    # Prepare source data with SCD2 columns\n",
    "    current_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    source_enhanced = source_df \\\n",
    "        .withColumn(\"record_start_date\", col(\"eligibility_start_date\")) \\\n",
    "        .withColumn(\"record_end_date\", lit(\"9999-12-31\")) \\\n",
    "        .withColumn(\"is_current_record\", lit(True)) \\\n",
    "        .withColumn(\"created_timestamp\", current_timestamp())\n",
    "    \n",
    "    print(\"Source eligibility changes:\")\n",
    "    source_enhanced.show()\n",
    "    \n",
    "    # Find records that have changed\n",
    "    # Join current active records with source to identify changes\n",
    "    comparison_df = active_records.alias(\"current\").join(\n",
    "        source_enhanced.alias(\"new\"),\n",
    "        col(\"current.member_id\") == col(\"new.member_id\"),\n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    # Identify what constitutes a change for eligibility\n",
    "    changed_records = comparison_df.filter(\n",
    "        (col(\"current.eligibility_status\") != col(\"new.eligibility_status\")) |\n",
    "        (col(\"current.eligibility_start_date\") != col(\"new.eligibility_start_date\")) |\n",
    "        (col(\"current.eligibility_end_date\") != col(\"new.eligibility_end_date\"))\n",
    "    ).select(\"new.*\")\n",
    "    \n",
    "    print(f\"Records with eligibility changes: {changed_records.count()}\")\n",
    "    \n",
    "    if changed_records.count() > 0:\n",
    "        changed_member_ids = changed_records.select(\"member_id\").distinct()\n",
    "        \n",
    "        # Step 1: Close current records for changed members\n",
    "        expired_records = current_eligibility.join(changed_member_ids, \"member_id\", \"inner\") \\\n",
    "            .withColumn(\"record_end_date\", lit(current_date)) \\\n",
    "            .withColumn(\"is_current_record\", lit(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "294fe348-c6a2-40fb-8408-f1ec21798fff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, current_timestamp, when, max, to_date\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "def implement_eligibility_scd2(target_table, source_df, key_column=\"member_id\"):\n",
    "    \"\"\"\n",
    "    Implement SCD Type 2 for eligibility table with proper healthcare date handling\n",
    "    \n",
    "    This tracks:\n",
    "    - Coverage terminations and reactivations\n",
    "    - Plan changes\n",
    "    - Eligibility period overlaps\n",
    "    - Compliance audit trail\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== ELIGIBILITY SCD TYPE 2 IMPLEMENTATION ===\")\n",
    "    \n",
    "    # Read current eligibility table\n",
    "    try:\n",
    "        current_eligibility = spark.table(target_table)\n",
    "        \n",
    "        # Add SCD2 columns if they don't exist\n",
    "        if \"is_current_record\" not in current_eligibility.columns:\n",
    "            current_eligibility = current_eligibility \\\n",
    "                .withColumn(\"record_start_date\", col(\"eligibility_start_date\")) \\\n",
    "                .withColumn(\"record_end_date\", lit(\"9999-12-31\")) \\\n",
    "                .withColumn(\"is_current_record\", lit(True)) \\\n",
    "                .withColumn(\"change_reason\", lit(\"Initial Load\")) \\\n",
    "                .withColumn(\"version_number\", lit(1)) \\\n",
    "                .withColumn(\"created_timestamp\", current_timestamp())\n",
    "    except Exception:\n",
    "        # If SCD2 table doesn't exist, create from base table\n",
    "        current_eligibility = spark.table(\"healthanalytics.eligibility\")\n",
    "        \n",
    "        # Add SCD2 columns to existing data\n",
    "        current_eligibility = current_eligibility \\\n",
    "            .withColumn(\"record_start_date\", col(\"eligibility_start_date\")) \\\n",
    "            .withColumn(\"record_end_date\", lit(\"9999-12-31\")) \\\n",
    "            .withColumn(\"is_current_record\", lit(True)) \\\n",
    "            .withColumn(\"change_reason\", lit(\"Initial Load\")) \\\n",
    "            .withColumn(\"version_number\", lit(1)) \\\n",
    "            .withColumn(\"created_timestamp\", current_timestamp())\n",
    "        \n",
    "        # Save initial SCD2 table\n",
    "        current_eligibility.write.mode(\"overwrite\").saveAsTable(f\"{target_table}_scd2\")\n",
    "        print(\"Created initial SCD2 eligibility table\")\n",
    "    \n",
    "    # Display current active eligibility records\n",
    "    active_records = current_eligibility.filter(col(\"is_current_record\") == True)\n",
    "    print(f\"Current active eligibility records: {active_records.count()}\")\n",
    "    display(active_records)\n",
    "    \n",
    "    # Prepare source data with SCD2 columns\n",
    "    current_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    source_enhanced = source_df \\\n",
    "        .withColumn(\"record_start_date\", to_date(col(\"eligibility_start_date\"), \"M/d/yyyy\")) \\\n",
    "        .withColumn(\"record_end_date\", lit(\"9999-12-31\")) \\\n",
    "        .withColumn(\"is_current_record\", lit(True)) \\\n",
    "        .withColumn(\"created_timestamp\", current_timestamp())\n",
    "    \n",
    "    print(\"Source eligibility changes:\")\n",
    "    display(source_enhanced)\n",
    "    \n",
    "    # Find records that have changed\n",
    "    # Join current active records with source to identify changes\n",
    "    comparison_df = active_records.alias(\"current\").join(\n",
    "        source_enhanced.alias(\"new\"),\n",
    "        col(\"current.member_id\") == col(\"new.member_id\"),\n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    # Identify what constitutes a change for eligibility\n",
    "    changed_records = comparison_df.filter(\n",
    "        (col(\"current.eligibility_status\") != col(\"new.eligibility_status\")) |\n",
    "        (col(\"current.eligibility_start_date\") != col(\"new.eligibility_start_date\")) |\n",
    "        (col(\"current.eligibility_end_date\") != col(\"new.eligibility_end_date\"))\n",
    "    ).select(\"new.*\")\n",
    "    \n",
    "    print(f\"Records with eligibility changes: {changed_records.count()}\")\n",
    "    \n",
    "    if changed_records.count() > 0:\n",
    "        changed_member_ids = changed_records.select(\"member_id\").distinct()\n",
    "        \n",
    "        # Step 1: Close current records for changed members\n",
    "        expired_records = current_eligibility.join(changed_member_ids, \"member_id\", \"inner\") \\\n",
    "            .withColumn(\"record_end_date\", lit(current_date)) \\\n",
    "            .withColumn(\"is_current_record\", lit(False))\n",
    "        \n",
    "        # Step 2: Keep unchanged records as-is\n",
    "        unchanged_records = current_eligibility.join(changed_member_ids, \"member_id\", \"left_anti\")\n",
    "        \n",
    "        # Step 3: Get max version numbers for changed members\n",
    "        max_versions = current_eligibility.groupBy(\"member_id\").agg(\n",
    "            max(\"version_number\").alias(\"max_version\")\n",
    "        )\n",
    "        \n",
    "        # Step 4: Create new records with incremented version and change reason\n",
    "        new_versions = changed_records.join(max_versions, \"member_id\", \"left\") \\\n",
    "            .withColumn(\"version_number\", col(\"max_version\") + 1) \\\n",
    "            .withColumn(\"change_reason\", \n",
    "                when(col(\"eligibility_status\") == \"Terminated\", \"Coverage Terminated\")\n",
    "                .when(col(\"eligibility_status\") == \"Active\", \"Coverage Activated\")\n",
    "                .when(col(\"eligibility_status\") == \"Suspended\", \"Coverage Suspended\")\n",
    "                .otherwise(\"Eligibility Update\")\n",
    "            ).drop(\"max_version\")\n",
    "        \n",
    "        # Step 5: Handle completely new members\n",
    "        new_members = source_enhanced.join(\n",
    "            current_eligibility.select(\"member_id\").distinct(),\n",
    "            \"member_id\",\n",
    "            \"left_anti\"\n",
    "        ).withColumn(\"version_number\", lit(1)) \\\n",
    "         .withColumn(\"change_reason\", lit(\"New Enrollment\"))\n",
    "        \n",
    "        # Combine all records\n",
    "        final_eligibility = unchanged_records \\\n",
    "            .union(expired_records) \\\n",
    "            .union(new_versions) \\\n",
    "            .union(new_members)\n",
    "    \n",
    "    else:\n",
    "        # No changes, just add new members\n",
    "        new_members = source_enhanced.join(\n",
    "            current_eligibility.select(\"member_id\").distinct(),\n",
    "            \"member_id\", \n",
    "            \"left_anti\"\n",
    "        ).withColumn(\"version_number\", lit(1)) \\\n",
    "         .withColumn(\"change_reason\", lit(\"New Enrollment\"))\n",
    "        \n",
    "        final_eligibility = current_eligibility.union(new_members)\n",
    "    \n",
    "    # Save updated SCD2 table\n",
    "    final_eligibility.write.mode(\"overwrite\").saveAsTable(f\"{target_table}_scd2\")\n",
    "    \n",
    "    print(\"=== UPDATED ELIGIBILITY SCD2 TABLE ===\")\n",
    "    result_df = spark.table(f\"{target_table}_scd2\")\n",
    "    result_df.orderBy(\"member_id\", \"version_number\")\n",
    "    display(result_df)\n",
    "    \n",
    "    # Show summary of changes\n",
    "    print(\"=== CHANGE SUMMARY ===\")\n",
    "    change_summary = result_df.groupBy(\"change_reason\").count().orderBy(\"count\", ascending=False)\n",
    "    display(change_summary)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Create sample eligibility changes (realistic healthcare scenarios)\n",
    "eligibility_changes = [\n",
    "    # Member 111260497: Terminated coverage\n",
    "    (1, 111260497, \"1/1/2023\", \"6/30/2024\", \"Terminated\"),\n",
    "    \n",
    "    # Member 123456789: Suspended then reactivated  \n",
    "    (2, 123456789, \"1/1/2023\", \"12/31/2024\", \"Suspended\"),\n",
    "    \n",
    "    # Member 987654321: Extended coverage period\n",
    "    (3, 987654321, \"1/1/2023\", \"12/31/2025\", \"Active\"),\n",
    "    \n",
    "    # New member enrollment\n",
    "    (4, 555777888, \"7/1/2024\", \"12/31/2024\", \"Active\"),\n",
    "    \n",
    "    # Member with gap in coverage (terminated then reactivated)\n",
    "    (5, 444555666, \"8/1/2024\", \"12/31/2024\", \"Active\")\n",
    "]\n",
    "\n",
    "eligibility_schema = StructType([\n",
    "    StructField(\"eligibility_id\", IntegerType(), True),\n",
    "    StructField(\"member_id\", IntegerType(), True),\n",
    "    StructField(\"eligibility_start_date\", StringType(), True),\n",
    "    StructField(\"eligibility_end_date\", StringType(), True),\n",
    "    StructField(\"eligibility_status\", StringType(), True)\n",
    "])\n",
    "\n",
    "eligibility_updates = spark.createDataFrame(eligibility_changes, eligibility_schema)\n",
    "\n",
    "print(\"=== ELIGIBILITY CHANGES TO PROCESS ===\")\n",
    "display(eligibility_updates)\n",
    "\n",
    "# Apply SCD Type 2 to eligibility\n",
    "eligibility_scd2_result = implement_eligibility_scd2(\n",
    "    \"healthanalytics.eligibility\",\n",
    "    eligibility_updates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0828e92-bf28-4331-9d75-f093e9996096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "def implement_provider_scd1(target_table, source_df, key_column=\"provider_id\"):\n",
    "    \"\"\"\n",
    "    Implement SCD Type 1 for provider table - practice location changes\n",
    "    \n",
    "    This overwrites:\n",
    "    - Practice location changes (current location is sufficient)\n",
    "    - Contact information updates  \n",
    "    - Administrative corrections\n",
    "    \n",
    "    This preserves:\n",
    "    - Provider specialty (might need history)\n",
    "    - PCP status (might need history)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== PROVIDER SCD TYPE 1 IMPLEMENTATION ===\")\n",
    "    \n",
    "    # Read current provider table\n",
    "    current_providers = spark.table(target_table)\n",
    "    print(\"Current provider table:\")\n",
    "    current_providers.show()\n",
    "    \n",
    "    print(\"Provider location changes to apply:\")\n",
    "    source_df.show()\n",
    "    \n",
    "    # Identify what columns to update (SCD Type 1 columns)\n",
    "    scd1_columns = [\"practice_location\", \"name\"]  # Location and name corrections\n",
    "    \n",
    "    # Show before state\n",
    "    print(\"=== BEFORE CHANGES ===\")\n",
    "    before_changes = current_providers.filter(\n",
    "        col(key_column).isin([row[key_column] for row in source_df.collect()])\n",
    "    )\n",
    "    before_changes.show()\n",
    "    \n",
    "    # For SCD Type 1, we simply merge/upsert the changes\n",
    "    # Get records that are not being updated\n",
    "    unchanged_providers = current_providers.join(\n",
    "        source_df.select(key_column),\n",
    "        key_column,\n",
    "        \"left_anti\"\n",
    "    )\n",
    "    \n",
    "    # Combine unchanged records with all source records (updated + new)\n",
    "    updated_providers = unchanged_providers.union(source_df)\n",
    "    \n",
    "    # Alternative approach using Delta merge (if available)\n",
    "    try:\n",
    "        from delta.tables import DeltaTable\n",
    "        \n",
    "        # Try Delta Lake merge for better performance\n",
    "        delta_table = DeltaTable.forName(spark, target_table)\n",
    "        \n",
    "        # Build update dictionary for SCD1 columns\n",
    "        update_dict = {col: f\"source.{col}\" for col in scd1_columns}\n",
    "        update_dict[\"Provider_Plan_ID\"] = \"source.Provider_Plan_ID\"\n",
    "        update_dict[\"specialty\"] = \"source.specialty\"\n",
    "        update_dict[\"is_pcp\"] = \"source.is_pcp\"\n",
    "        update_dict[\"ID\"] = \"source.ID\"\n",
    "        update_dict[\"TaxID\"] = \"source.TaxID\"\n",
    "        \n",
    "        delta_table.alias(\"target\") \\\n",
    "            .merge(\n",
    "                source_df.alias(\"source\"),\n",
    "                f\"target.{key_column} = source.{key_column}\"\n",
    "            ) \\\n",
    "            .whenMatchedUpdate(set=update_dict) \\\n",
    "            .whenNotMatchedInsertAll() \\\n",
    "            .execute()\n",
    "        \n",
    "        print(\"Used Delta Lake merge for SCD Type 1\")\n",
    "        result_df = spark.table(target_table)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Delta merge not available, using DataFrame operations: {e}\")\n",
    "        \n",
    "        # Save using DataFrame operations\n",
    "        updated_providers.write.mode(\"overwrite\").saveAsTable(f\"{target_table}_scd1_updated\")\n",
    "        result_df = spark.table(f\"{target_table}_scd1_updated\")\n",
    "    \n",
    "    # Show after state\n",
    "    print(\"=== AFTER CHANGES ===\")\n",
    "    after_changes = result_df.filter(\n",
    "        col(key_column).isin([row[key_column] for row in source_df.collect()])\n",
    "    )\n",
    "    after_changes.show()\n",
    "    \n",
    "    # Show change summary\n",
    "    print(\"=== CHANGE SUMMARY ===\")\n",
    "    total_providers = result_df.count()\n",
    "    updated_count = source_df.count()\n",
    "    new_providers = source_df.join(current_providers.select(key_column), key_column, \"left_anti\").count()\n",
    "    \n",
    "    print(f\"Total providers after update: {total_providers}\")\n",
    "    print(f\"Records processed: {updated_count}\")\n",
    "    print(f\"New providers added: {new_providers}\")\n",
    "    print(f\"Existing providers updated: {updated_count - new_providers}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Create realistic provider location changes\n",
    "provider_changes = [\n",
    "    # Dr. James Wilson moved to new location\n",
    "    (2001, \"Dr. James Wilson\", \"Family Medicine\", \"Downtown Medical Center\", 1, \"PR0001\", 1, 957974335),\n",
    "    \n",
    "    # Dr. Sarah Johnson name correction and location change  \n",
    "    (2002, \"Dr. Sarah M. Johnson\", \"Pediatrics\", \"Children's Hospital East Wing\", 1, \"PR0002\", 2, 123456789),\n",
    "    \n",
    "    # Existing provider location change\n",
    "    (2003, \"Dr. Michael Chen\", \"Cardiology\", \"Heart & Vascular Institute\", 0, \"PR0003\", 3, 987654321),\n",
    "    \n",
    "    # New provider joining the network\n",
    "    (2004, \"Dr. Lisa Rodriguez\", \"Orthopedics\", \"Sports Medicine Center\", 0, \"PR0004\", 4, 555666777),\n",
    "    \n",
    "    # Provider location consolidation\n",
    "    (2005, \"Dr. Robert Kim\", \"Internal Medicine\", \"North Clinic\", 1, \"PR0005\", 5, 111222333)\n",
    "]\n",
    "\n",
    "provider_schema = StructType([\n",
    "    StructField(\"Provider_Plan_ID\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"specialty\", StringType(), True),\n",
    "    StructField(\"practice_location\", StringType(), True),\n",
    "    StructField(\"is_pcp\", IntegerType(), True),\n",
    "    StructField(\"provider_id\", StringType(), True),\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"TaxID\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "provider_updates = spark.createDataFrame(provider_changes, provider_schema)\n",
    "\n",
    "print(\"=== PROVIDER LOCATION CHANGES TO PROCESS ===\")\n",
    "provider_updates.show(truncate=False)\n",
    "\n",
    "# Apply SCD Type 1 to provider data\n",
    "provider_scd1_result = implement_provider_scd1(\n",
    "    \"default.providers\",\n",
    "    provider_updates\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ELIG STATUS",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
